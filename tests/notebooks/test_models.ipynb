{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d92c875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration loaded\n",
      "   API Key: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import toml\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load config\n",
    "project_root = Path('.').resolve().parent.parent\n",
    "config = toml.load(project_root / 'config.toml')\n",
    "dial_config = config.get('DIAL_API', {})\n",
    "\n",
    "dial_api_endpoint = dial_config.get('DIAL_API_ENDPOINT', 'https://ai-proxy.lab.epam.com/openai/deployments/{model_id}/chat/completions')\n",
    "dial_models_endpoint = 'https://ai-proxy.lab.epam.com/openai/models'\n",
    "api_key = os.getenv('DIAL_API_KEY')\n",
    "\n",
    "print('✅ Configuration loaded')\n",
    "print(f'   API Key: {bool(api_key)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681edd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching models...\n",
      "✅ Retrieved 98 models\n",
      "\n",
      "Model types:\n",
      "  unknown               98\n"
     ]
    }
   ],
   "source": [
    "# Retrieve ALL models\n",
    "print('Fetching models...')\n",
    "headers = {'api-key': api_key}\n",
    "response = requests.get(dial_models_endpoint, headers=headers, timeout=10)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    all_models = response.json().get('data', [])\n",
    "    print(f'✅ Retrieved {len(all_models)} models\\n')\n",
    "    \n",
    "    # Analyze types\n",
    "    model_types = {}\n",
    "    for model in all_models:\n",
    "        mtype = model.get('type', 'unknown')\n",
    "        model_types[mtype] = model_types.get(mtype, 0) + 1\n",
    "    \n",
    "    print('Model types:')\n",
    "    for mtype, count in sorted(model_types.items(), key=lambda x: -x[1]):\n",
    "        print(f'  {mtype:<20} {count:3d}')\n",
    "else:\n",
    "    print(f'Error: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d2365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered: 73 text-generating models\n",
      "\n",
      "Models:\n",
      "   1. anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "   2. anthropic.claude-3-7-sonnet-20250219-v1:0-with-thinking\n",
      "   3. anthropic.claude-haiku-4-5-20251001-v1:0\n",
      "   4. anthropic.claude-haiku-4-5-20251001-v1:0-with-thinking\n",
      "   5. anthropic.claude-opus-4-1-20250805-v1:0\n",
      "   6. anthropic.claude-opus-4-1-20250805-v1:0-with-thinking\n",
      "   7. anthropic.claude-opus-4-20250514-v1:0\n",
      "   8. anthropic.claude-opus-4-20250514-v1:0-with-thinking\n",
      "   9. anthropic.claude-opus-4-5-20251101-v1:0\n",
      "  10. anthropic.claude-opus-4-5-20251101-v1:0-with-thinking\n",
      "  11. anthropic.claude-sonnet-4-20250514-v1:0\n",
      "  12. anthropic.claude-sonnet-4-20250514-v1:0-with-thinking\n",
      "  13. anthropic.claude-sonnet-4-5-20250929-v1:0\n",
      "  14. anthropic.claude-sonnet-4-5-20250929-v1:0-with-thinking\n",
      "  15. anthropic.claude-v3-5-haiku\n",
      "  16. anthropic.claude-v3-5-sonnet\n",
      "  17. anthropic.claude-v3-5-sonnet-v1\n",
      "  18. anthropic.claude-v3-5-sonnet-v2\n",
      "  19. anthropic.claude-v3-haiku\n",
      "  20. anthropic.claude-v3-opus\n",
      "  21. claude-3-5-haiku@20241022\n",
      "  22. claude-3-5-sonnet-v2@20241022\n",
      "  23. claude-3-5-sonnet-v2@latest\n",
      "  24. claude-3-5-sonnet@20240620\n",
      "  25. claude-3-7-sonnet@20250219\n",
      "  26. claude-haiku-4-5@20251001\n",
      "  27. claude-opus-4-1@20250805\n",
      "  28. claude-opus-4-5@20251101\n",
      "  29. claude-opus-4@20250514\n",
      "  30. claude-sonnet-4-5@20250929\n",
      "  31. claude-sonnet-4@20250514\n",
      "  32. deepseek-r1\n",
      "  33. deepseek.r1-v1:0\n",
      "  34. gemini-2.0-flash\n",
      "  35. gemini-2.0-flash-exp\n",
      "  36. gemini-2.0-flash-exp-google-search\n",
      "  37. gemini-2.0-flash-lite\n",
      "  38. gemini-2.5-flash\n",
      "  39. gemini-2.5-flash-lite\n",
      "  40. gemini-2.5-pro\n",
      "  41. gemini-2.5-pro-google-search\n",
      "  42. gemini-3-pro-preview\n",
      "  43. gemini-3-pro-preview-google-search\n",
      "  44. gpt-4\n",
      "  45. gpt-4.1-2025-04-14\n",
      "  46. gpt-4.1-mini-2025-04-14\n",
      "  47. gpt-4.1-nano-2025-04-14\n",
      "  48. gpt-4o\n",
      "  49. gpt-4o-2024-05-13\n",
      "  50. gpt-4o-2024-08-06\n",
      "  51. gpt-4o-2024-11-20\n",
      "  52. gpt-4o-mini-2024-07-18\n",
      "  53. gpt-5-2025-08-07\n",
      "  54. gpt-5-2025-08-07-reasoning\n",
      "  55. gpt-5-chat-2025-08-07\n",
      "  56. gpt-5-codex-2025-09-15\n",
      "  57. gpt-5-codex-2025-09-15-reasoning\n",
      "  58. gpt-5-mini-2025-08-07\n",
      "  59. gpt-5-mini-2025-08-07-reasoning\n",
      "  60. gpt-5-nano-2025-08-07\n",
      "  61. gpt-5-nano-2025-08-07-reasoning\n",
      "  62. gpt-5.1-2025-11-13\n",
      "  63. gpt-5.1-2025-11-13-reasoning\n",
      "  64. gpt-5.1-chat-2025-11-13\n",
      "  65. gpt-5.1-chat-2025-11-13-reasoning\n",
      "  66. gpt-5.1-codex-2025-11-13\n",
      "  67. gpt-5.1-codex-2025-11-13-reasoning\n",
      "  68. gpt-5.1-codex-mini-2025-11-13\n",
      "  69. gpt-5.1-codex-mini-2025-11-13-reasoning\n",
      "  70. gpt-oss-120b\n",
      "  71. meta.llama4-maverick-17b-instruct-v1:0\n",
      "  72. meta.llama4-scout-17b-instruct-v1:0\n",
      "  73. rlab-qwen3-32b\n"
     ]
    }
   ],
   "source": [
    "# Filter for text-generating models\n",
    "def is_text_gen(model_id: str) -> bool:\n",
    "    exclude = ['embedding', 'embed', 'vision-', 'image', 'dall-e', 'whisper', 'tts', 'audio']\n",
    "    include = ['gpt', 'claude', 'gemini', 'llama', 'mistral', 'deepseek', 'phi', 'qwen']\n",
    "    \n",
    "    model_lower = model_id.lower()\n",
    "    if any(p in model_lower for p in exclude):\n",
    "        return False\n",
    "    return any(p in model_lower for p in include)\n",
    "\n",
    "text_gen = [m for m in all_models if is_text_gen(m.get('id', ''))]\n",
    "text_gen = sorted(text_gen, key=lambda x: x.get('id', ''))\n",
    "\n",
    "print(f'\\nFiltered: {len(text_gen)} text-generating models\\n')\n",
    "print('Models:')\n",
    "for i, m in enumerate(text_gen, 1):\n",
    "    print(f'  {i:2d}. {m.get(\"id\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbacec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 73 models...\n",
      "\n",
      "[ 1/73] anthropic.claude-3-7-sonnet-20250219-v1:0... ❌ Blocked\n",
      "[ 2/73] anthropic.claude-3-7-sonnet-20250219-v1:0-with-thinking... ❌ Blocked\n",
      "[ 3/73] anthropic.claude-haiku-4-5-20251001-v1:0... ✅ Available\n",
      "[ 4/73] anthropic.claude-haiku-4-5-20251001-v1:0-with-thinking... ❌ Blocked\n",
      "[ 5/73] anthropic.claude-opus-4-1-20250805-v1:0... ❌ Blocked\n",
      "[ 6/73] anthropic.claude-opus-4-1-20250805-v1:0-with-thinking... ❌ Blocked\n",
      "[ 7/73] anthropic.claude-opus-4-20250514-v1:0... ❌ Blocked\n",
      "[ 8/73] anthropic.claude-opus-4-20250514-v1:0-with-thinking... ❌ Blocked\n",
      "[ 9/73] anthropic.claude-opus-4-5-20251101-v1:0... ❌ Blocked\n",
      "[10/73] anthropic.claude-opus-4-5-20251101-v1:0-with-thinking... ❌ Blocked\n",
      "[11/73] anthropic.claude-sonnet-4-20250514-v1:0... ❌ Blocked\n",
      "[12/73] anthropic.claude-sonnet-4-20250514-v1:0-with-thinking... ❌ Blocked\n",
      "[13/73] anthropic.claude-sonnet-4-5-20250929-v1:0... ❌ Blocked\n",
      "[14/73] anthropic.claude-sonnet-4-5-20250929-v1:0-with-thinking... ❌ Blocked\n",
      "[15/73] anthropic.claude-v3-5-haiku... ❌ Blocked\n",
      "[16/73] anthropic.claude-v3-5-sonnet... ❌ Blocked\n",
      "[17/73] anthropic.claude-v3-5-sonnet-v1... ❌ Blocked\n",
      "[18/73] anthropic.claude-v3-5-sonnet-v2... ❌ Blocked\n",
      "[19/73] anthropic.claude-v3-haiku... ❌ Blocked\n",
      "[20/73] anthropic.claude-v3-opus... ❌ Blocked\n",
      "[21/73] claude-3-5-haiku@20241022... ✅ Available\n",
      "[22/73] claude-3-5-sonnet-v2@20241022... ❌ Blocked\n",
      "[23/73] claude-3-5-sonnet-v2@latest... ❌ Blocked\n",
      "[24/73] claude-3-5-sonnet@20240620... ❌ Blocked\n",
      "[25/73] claude-3-7-sonnet@20250219... ✅ Available\n",
      "[26/73] claude-haiku-4-5@20251001... ✅ Available\n",
      "[27/73] claude-opus-4-1@20250805... ❌ Blocked\n",
      "[28/73] claude-opus-4-5@20251101... ❌ Blocked\n",
      "[29/73] claude-opus-4@20250514... ❌ Blocked\n",
      "[30/73] claude-sonnet-4-5@20250929... ❌ Blocked\n",
      "[31/73] claude-sonnet-4@20250514... ✅ Available\n",
      "[32/73] deepseek-r1... ✅ Available\n",
      "[33/73] deepseek.r1-v1:0... ❌ Blocked\n",
      "[34/73] gemini-2.0-flash... "
     ]
    }
   ],
   "source": [
    "# Test models\n",
    "def test_model(model_id: str) -> dict:\n",
    "    url = dial_api_endpoint.format(model_id=model_id)\n",
    "    headers = {'Api-Key': api_key, 'Content-Type': 'application/json'}\n",
    "    data = {'messages': [{'role': 'user', 'content': 'test'}], 'max_tokens': 5}\n",
    "    \n",
    "    try:\n",
    "        start = datetime.now()\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=15)\n",
    "        elapsed = (datetime.now() - start).total_seconds()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return {'model': model_id, 'status': '✅ Available', 'time': round(elapsed, 2), 'code': 200}\n",
    "        elif response.status_code == 403:\n",
    "            return {'model': model_id, 'status': '❌ Blocked', 'time': round(elapsed, 2), 'code': 403}\n",
    "        elif response.status_code == 429:\n",
    "            return {'model': model_id, 'status': '⏳ Quota', 'time': round(elapsed, 2), 'code': 429}\n",
    "        else:\n",
    "            return {'model': model_id, 'status': f'❌ Error {response.status_code}', 'time': round(elapsed, 2), 'code': response.status_code}\n",
    "    except Exception as e:\n",
    "        return {'model': model_id, 'status': '❌ Error', 'time': None, 'code': None, 'error': str(e)[:50]}\n",
    "\n",
    "print(f'Testing {len(text_gen)} models...\\n')\n",
    "results = []\n",
    "\n",
    "for i, model in enumerate(text_gen, 1):\n",
    "    model_id = model.get('id')\n",
    "    print(f'[{i:2d}/{len(text_gen)}] {model_id}...', end=' ', flush=True)\n",
    "    result = test_model(model_id)\n",
    "    results.append(result)\n",
    "    print(result['status'])\n",
    "\n",
    "print(f'\\n✅ Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e8995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "❌ Blocked             50\n",
      "✅ Available           19\n",
      "❌ Error 400            3\n",
      "❌ Error                1\n",
      "\n",
      "Total: 73 models tested\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "df = pd.DataFrame(results)\n",
    "status_counts = df['status'].value_counts()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('SUMMARY')\n",
    "print('='*60)\n",
    "for status, count in status_counts.items():\n",
    "    print(f'{status:20s} {count:3d}')\n",
    "\n",
    "print(f'\\nTotal: {len(df)} models tested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7ebb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BLOCKED MODELS - RESPONSE DETAILS\n",
      "============================================================\n",
      "\n",
      "Found 50 blocked models\n",
      "\n",
      "\n",
      "anthropic.claude-3-7-sonnet-20250219-v1:0:\n",
      "  Status Code: 403\n",
      "  Headers: {'Date': 'Mon, 15 Dec 2025 10:08:34 GMT', 'Content-Length': '83', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'content-encoding': 'gzip', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains'}\n",
      "  Body: {'error': {'message': 'Access denied', 'display_message': 'Access denied', 'code': '403'}}\n",
      "\n",
      "anthropic.claude-3-7-sonnet-20250219-v1:0-with-thinking:\n",
      "  Status Code: 403\n",
      "  Headers: {'Date': 'Mon, 15 Dec 2025 10:08:35 GMT', 'Content-Length': '83', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'content-encoding': 'gzip', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains'}\n",
      "  Body: {'error': {'message': 'Access denied', 'display_message': 'Access denied', 'code': '403'}}\n",
      "\n",
      "anthropic.claude-haiku-4-5-20251001-v1:0-with-thinking:\n",
      "  Status Code: 403\n",
      "  Headers: {'Date': 'Mon, 15 Dec 2025 10:08:35 GMT', 'Content-Length': '83', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'content-encoding': 'gzip', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains'}\n",
      "  Body: {'error': {'message': 'Access denied', 'display_message': 'Access denied', 'code': '403'}}\n",
      "\n",
      "anthropic.claude-opus-4-1-20250805-v1:0:\n",
      "  Status Code: 403\n",
      "  Headers: {'Date': 'Mon, 15 Dec 2025 10:08:36 GMT', 'Content-Length': '83', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'content-encoding': 'gzip', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains'}\n",
      "  Body: {'error': {'message': 'Access denied', 'display_message': 'Access denied', 'code': '403'}}\n",
      "\n",
      "anthropic.claude-opus-4-1-20250805-v1:0-with-thinking:\n",
      "  Status Code: 403\n",
      "  Headers: {'Date': 'Mon, 15 Dec 2025 10:08:36 GMT', 'Content-Length': '83', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'content-encoding': 'gzip', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains'}\n",
      "  Body: {'error': {'message': 'Access denied', 'display_message': 'Access denied', 'code': '403'}}\n"
     ]
    }
   ],
   "source": [
    "# Show blocked model responses\n",
    "print('\\n' + '='*60)\n",
    "print('BLOCKED MODELS - RESPONSE DETAILS')\n",
    "print('='*60)\n",
    "\n",
    "blocked_models = [r['model'] for r in results if '❌ Blocked' in r['status']]\n",
    "print(f'\\nFound {len(blocked_models)} blocked models\\n')\n",
    "\n",
    "for model_id in blocked_models[:5]:  # Show first 5\n",
    "    url = dial_api_endpoint.format(model_id=model_id)\n",
    "    headers = {'Api-Key': api_key, 'Content-Type': 'application/json'}\n",
    "    data = {'messages': [{'role': 'user', 'content': 'test'}], 'max_tokens': 5}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=15)\n",
    "        print(f'\\n{model_id}:')\n",
    "        print(f'  Status Code: {response.status_code}')\n",
    "        print(f'  Headers: {dict(response.headers)}')\n",
    "        try:\n",
    "            print(f'  Body: {response.json()}')\n",
    "        except:\n",
    "            print(f'  Body (text): {response.text[:200]}')\n",
    "    except Exception as e:\n",
    "        print(f'\\n{model_id}: Error - {e}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
